---
title: Supervising Variational Autoencoder Latent Representations with Language
openreview: LVYEjD25tZ
abstract: Supervising latent representations of data is of great interest for modern
  multi-modal generative machine learning.  In this work, we propose two new methods
  to use text to condition the latent representations of a VAE, and evaluate them
  on a novel conditional image-generation benchmark task. We find that the applied
  methods can be used to generate highly accurate reconstructed images through language
  querying with minimal compute resources. Our methods are quantitatively successful
  at conforming to textually-supervised attributes of an image while keeping unsupervised
  attributes constant. At large, we present critical observations on disentanglement
  between supervised and unsupervised properties of images and identify common barriers
  to effective disentanglement.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lu24a
month: 0
tex_title: Supervising Variational Autoencoder Latent Representations with Language
firstpage: 267
lastpage: 278
page: 267-278
order: 267
cycles: false
bibtex_author: Lu, Thomas and Marathe, Aboli and Martin, Ada
author:
- given: Thomas
  family: Lu
- given: Aboli
  family: Marathe
- given: Ada
  family: Martin
date: 2024-05-14
address:
container-title: 'Proceedings of UniReps: the First Workshop on Unifying Representations
  in Neural Models'
volume: '243'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 5
  - 14
pdf: https://proceedings.mlr.press/v243/lu24a/lu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
