---
title: Linearly Structured World Representations in Maze-Solving Transformers
openreview: pZakRK1QHU
abstract: The emergence of seemingly similar representations across tasks and neural
  architectures suggests that convergent properties may underlie sophisticated behavior.
  One form of representation that seems particularly fundamental to reasoning in many
  artificial (and perhaps natural) networks is the formation of world models, which
  decompose observed task structures into re-usable perceptual primitives and task-relevant
  relations. In this work, we show that auto-regressive transformers tasked with solving
  mazes learn to linearly represent the structure of mazes, and that the formation
  of these representations coincides with a sharp increase in generalization performance.
  Furthermore, we find preliminary evidence for Adjacency Heads which may play a role
  in computing valid paths through mazes.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ivanitskiy24a
month: 0
tex_title: Linearly Structured World Representations in Maze-Solving Transformers
firstpage: 133
lastpage: 143
page: 133-143
order: 133
cycles: false
bibtex_author: Ivanitskiy, Michael and Spies, Alexander F. and R\"auker, Tilman and
  Corlouer, Guillaume and Mathwin, Christopher and Quirke, Lucia and Rager, Can and
  Shah, Rusheb and Valentine, Dan and Behn, Cecilia Diniz and Inoue, Katsumi and Fung,
  Samy Wu
author:
- given: Michael
  family: Ivanitskiy
- given: Alexander F.
  family: Spies
- given: Tilman
  family: RÃ¤uker
- given: Guillaume
  family: Corlouer
- given: Christopher
  family: Mathwin
- given: Lucia
  family: Quirke
- given: Can
  family: Rager
- given: Rusheb
  family: Shah
- given: Dan
  family: Valentine
- given: Cecilia Diniz
  family: Behn
- given: Katsumi
  family: Inoue
- given: Samy Wu
  family: Fung
date: 2024-05-14
address:
container-title: 'Proceedings of UniReps: the First Workshop on Unifying Representations
  in Neural Models'
volume: '243'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 5
  - 14
pdf: https://proceedings.mlr.press/v243/ivanitskiy24a/ivanitskiy24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
