---
title: 'Bio-inspired parameter reuse: Exploiting inter-frame representation similarity
  with recurrence for accelerating temporal visual processing'
openreview: dpYcX84x6M
abstract: Feedforward neural networks are the dominant approach in current computer
  vision research. They typically do not incorporate recurrence, which is a prominent
  feature of biological vision brain circuitry. Inspired by biological findings, we
  introduce $\textbf{RecSlowFast}$, a recurrent slow-fast framework aimed at showing
  how recurrence can be useful for temporal visual processing. We perform a variable
  number of recurrent steps of certain layers in a network receiving input video frames,
  where each recurrent step is equivalent to a feedforward layer with weights reuse.
  By harnessing the hidden states extracted from the previous input frame, we reduce
  the computation cost by executing fewer recurrent steps on temporally correlated
  consecutive frames, while keeping good task accuracy. The early termination of the
  recurrence can be dynamically determined through newly introduced criteria based
  on the distance between hidden states and without using any auxiliary scheduler
  network. RecSlowFast  $\textbf{reuses a single set of parameters}$, unlike previous
  work which requires one computationally heavy network and one light network, to
  achieve the speed versus accuracy trade-off. Using a new $\textit{Temporal Pathfinder}$
  dataset proposed in this work, we evaluate RecSlowFast on a task to continuously
  detect the longest evolving contour in a video. The slow-fast inference mechanism
  speeds up the average frame per second by 279% on this dataset with comparable task
  accuracy using a desktop GPU. We further demonstrate a similar trend on CamVid,
  a video semantic segmentation dataset.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang24a
month: 0
tex_title: 'Bio-inspired parameter reuse: Exploiting inter-frame representation similarity
  with recurrence for accelerating temporal visual processing'
firstpage: 209
lastpage: 222
page: 209-222
order: 209
cycles: false
bibtex_author: Wang, Zuowen and Cheng, Longbiao and Ott, Joachim and Moure, Pehuen
  and Liu, Shih-Chii
author:
- given: Zuowen
  family: Wang
- given: Longbiao
  family: Cheng
- given: Joachim
  family: Ott
- given: Pehuen
  family: Moure
- given: Shih-Chii
  family: Liu
date: 2024-05-14
address:
container-title: 'Proceedings of UniReps: the First Workshop on Unifying Representations
  in Neural Models'
volume: '243'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 5
  - 14
pdf: https://proceedings.mlr.press/v243/wang24a/wang24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
